{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/conorgibbons147/cyclegan-map/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf cyclegan-map # use if changes are made to the repo and you need to reclone"
      ],
      "metadata": {
        "id": "I2ynbzpE15M0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4Qt8alUu2wR",
        "outputId": "f579db17-efda-41f8-a354-7aedb2e97d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cyclegan-map'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 75 (delta 25), reused 53 (delta 10), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (75/75), 6.13 MiB | 9.79 MiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/conorgibbons147/cyclegan-map.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import itertools\n",
        "import sys\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "0Dpo_b-v2JNT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append('/content/cyclegan-map/models')\n",
        "from generator import Generator\n",
        "from discriminator import Discriminator"
      ],
      "metadata": {
        "id": "99Jln8OjxRDA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append('/content/cyclegan-map')\n",
        "from dataset import ImageDataset\n",
        "from utils import weight_init, ReplayBuffer, sample_images"
      ],
      "metadata": {
        "id": "DxNioAyQwyUV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "epochs = 200\n",
        "batch_size = 1\n",
        "image_size = 256\n",
        "save_interval = 100  # how often to save images\n",
        "dataset_path = \"/content/cyclegan-map/data\""
      ],
      "metadata": {
        "id": "KiYYx7lz2nou"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create networks\n",
        "G_AB = Generator().to(device) # modern to vintage\n",
        "G_BA = Generator().to(device) # vintage to modern\n",
        "D_A = Discriminator().to(device) # check if fake vintage is real\n",
        "D_B = Discriminator().to(device) # check if fake modern is real\n",
        "\n",
        "# set weights for the networks\n",
        "G_AB.apply(weight_init)\n",
        "G_BA.apply(weight_init)\n",
        "D_A.apply(weight_init)\n",
        "D_B.apply(weight_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0lWqqcj2_c6",
        "outputId": "76c30c33-3e92-4944-b5ce-03d6e03a454b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (model): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# image loading setup\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.BICUBIC), # how each image will be transformed to make them standard\n",
        "    transforms.ToTensor(),  # Converts image from [0,255] to [0.0,1.0]\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Scales [0,1] to [-1,1]\n",
        "])\n",
        "\n",
        "train_dataset = ImageDataset(dataset_path, transform=transform, mode='train')\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataset = ImageDataset(dataset_path, transform=transform, mode='val')\n",
        "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "-A_NS_Xv5Awo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss functions\n",
        "criterion_GAN = nn.MSELoss()\n",
        "criterion_cycle = nn.L1Loss()\n",
        "criterion_identity = nn.L1Loss()\n",
        "\n",
        "lambda_cycle = 10.0               # lambdas are used to scale/weight the cycle and identity loss in our overall loss\n",
        "lambda_identity = 5.0"
      ],
      "metadata": {
        "id": "Zn8ypPlF551J"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizers\n",
        "optimizer_G = optim.Adam(itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D_A = optim.Adam(D_A.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D_B = optim.Adam(D_B.parameters(), lr=0.0002, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "id": "QxdBzsve6AQ1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replay buffers - ensures that the discriminator is fed older saved fake images instead of just new ones, improves model performance\n",
        "fake_A_buffer = ReplayBuffer()\n",
        "fake_B_buffer = ReplayBuffer()"
      ],
      "metadata": {
        "id": "1wV474mP6DWs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "for epoch in range(epochs):\n",
        "    for i, batch in enumerate(train_loader): # form: 0 img1  1 img2  2 img3 (this is what enumerate does, saves index as i)\n",
        "        real_A = batch['A'].to(device)\n",
        "        real_B = batch['B'].to(device)\n",
        "\n",
        "        # ----- Generators -----\n",
        "        optimizer_G.zero_grad() # clears gradients before backpropogating on the new batch\n",
        "\n",
        "        # identity loss\n",
        "        same_B = G_AB(real_B)\n",
        "        loss_identity_B = criterion_identity(same_B, real_B) * lambda_identity # testing how different a vintage map becomes when fed into the modern->vintage generator,\n",
        "                                                                               # should be the same in theory\n",
        "        same_A = G_BA(real_A)\n",
        "        loss_identity_A = criterion_identity(same_A, real_A) * lambda_identity # same for modern map when fed into vintage->modern generator\n",
        "\n",
        "        # GAN loss - testing loss of the fake images compared to a completely real image\n",
        "        fake_B = G_AB(real_A)\n",
        "        pred_fake_B = D_B(fake_B)\n",
        "        loss_GAN_AB = criterion_GAN(pred_fake_B, torch.ones_like(pred_fake_B)) # torch.ones_like() creates a tensor of same shape as pred_fake_B full of ones, acts as a\n",
        "                                                                               # completely real image since generator outputs 1s when an image is deemed real, takes MSE loss\n",
        "        fake_A = G_BA(real_B)\n",
        "        pred_fake_A = D_A(fake_A)\n",
        "        loss_GAN_BA = criterion_GAN(pred_fake_A, torch.ones_like(pred_fake_A))\n",
        "\n",
        "        # cycle loss - loss when fake image is converted back to it's previous map type (ex. comparing original modern to modern->vinatage->modern duplicate)\n",
        "        recov_A = G_BA(fake_B)\n",
        "        loss_cycle_A = criterion_cycle(recov_A, real_A) * lambda_cycle\n",
        "\n",
        "        recov_B = G_AB(fake_A)\n",
        "        loss_cycle_B = criterion_cycle(recov_B, real_B) * lambda_cycle\n",
        "\n",
        "        # calculating total loss across the entire process\n",
        "        loss_G = loss_identity_A + loss_identity_B + loss_GAN_AB + loss_GAN_BA + loss_cycle_A + loss_cycle_B\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ----- Discriminators -----\n",
        "        # A - testing how the real modern map compares to fake one\n",
        "        optimizer_D_A.zero_grad()\n",
        "\n",
        "        loss_real_A = criterion_GAN(D_A(real_A), torch.ones_like(D_A(real_A)))\n",
        "        fake_A_buffered = fake_A_buffer.push_and_pop(fake_A)\n",
        "        loss_fake_A = criterion_GAN(D_A(fake_A_buffered.detach()), torch.zeros_like(D_A(fake_A_buffered)))\n",
        "        loss_D_A = (loss_real_A + loss_fake_A) * 0.5\n",
        "        loss_D_A.backward()\n",
        "        optimizer_D_A.step()\n",
        "\n",
        "        # B - testing how the real vintage map compares to fake one\n",
        "        optimizer_D_B.zero_grad()\n",
        "\n",
        "        loss_real_B = criterion_GAN(D_B(real_B), torch.ones_like(D_B(real_B)))\n",
        "        fake_B_buffered = fake_B_buffer.push_and_pop(fake_B)\n",
        "        loss_fake_B = criterion_GAN(D_B(fake_B_buffered.detach()), torch.zeros_like(D_B(fake_B_buffered)))\n",
        "        loss_D_B = (loss_real_B + loss_fake_B) * 0.5\n",
        "        loss_D_B.backward()\n",
        "        optimizer_D_B.step()\n",
        "\n",
        "        # print statement\n",
        "        print(f\"[Epoch {epoch+1}/{epochs}] [Batch {i+1}/{len(train_loader)}] \"\n",
        "              f\"[D_A loss: {loss_D_A.item():.4f}] [D_B loss: {loss_D_B.item():.4f}] [G loss: {loss_G.item():.4f}]\")\n",
        "\n",
        "        # saving images\n",
        "        batches_done = epoch * len(train_loader) + i\n",
        "        if batches_done % save_interval == 0:\n",
        "            sample_images(batches_done, G_AB, G_BA, val_loader, device)"
      ],
      "metadata": {
        "id": "upUvzC8u6SsH",
        "outputId": "20563c90-cd67-4891-a6e0-60d2091b352e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (ipython-input-17-532692369.py, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-17-532692369.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    for epoch in range(epochs):\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvLTZ1Qrghb8iASvRqElDI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}